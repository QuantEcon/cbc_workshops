{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10668ec",
   "metadata": {},
   "source": [
    "# The Investment Problem via JAX\n",
    "\n",
    "#### Prepared for the CBC QuantEcon Workshop (2022)\n",
    "\n",
    "#### John Stachurski\n",
    "\n",
    "Re-implements the investment problem using JAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "475edccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import quantecon as qe\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b166336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 64 bit floats with JAX in order to match NumPy/Numba code\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43a557d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def successive_approx(T,                     # Operator (callable)\n",
    "                      x_0,                   # Initial condition\n",
    "                      tolerance=1e-6,        # Error tolerance\n",
    "                      max_iter=10_000,       # Max iteration bound\n",
    "                      print_step=25,         # Print at multiples\n",
    "                      verbose=False):        \n",
    "    x = x_0\n",
    "    error = tolerance + 1\n",
    "    k = 1\n",
    "    while error > tolerance and k <= max_iter:\n",
    "        x_new = T(x)\n",
    "        error = np.max(np.abs(x_new - x))\n",
    "        if verbose and k % print_step == 0:\n",
    "            print(f\"Completed iteration {k} with error {error}.\")\n",
    "        x = x_new\n",
    "        k += 1\n",
    "    if error > tolerance:\n",
    "        print(f\"Warning: Iteration hit upper bound {max_iter}.\")\n",
    "    elif verbose:\n",
    "        print(f\"Terminated successfully in {k} iterations.\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851380a7",
   "metadata": {},
   "source": [
    "### Primitives and Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad8fef48",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# A namedtuple definition for storing parameters and grids\n",
    "Model = namedtuple(\"Model\", \n",
    "                   (\"β\", \"a_0\", \"a_1\", \"γ\", \"c\",\n",
    "                    \"y_size\", \"z_size\", \"y_grid\", \"z_grid\", \"Q\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f07da7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_investment_model(\n",
    "        r=0.01,                              # Interest rate\n",
    "        a_0=10.0, a_1=1.0,                   # Demand parameters\n",
    "        γ=25.0, c=1.0,                       # Adjustment and unit cost \n",
    "        y_min=0.0, y_max=20.0, y_size=100,   # Grid for output\n",
    "        ρ=0.9, ν=1.0,                        # AR(1) parameters\n",
    "        z_size=150):                         # Grid size for shock\n",
    "    \"\"\"\n",
    "    A function that takes in parameters and returns an instance of Model that\n",
    "    contains data for the investment problem.\n",
    "    \"\"\"\n",
    "    β = 1/(1+r) \n",
    "    y_grid = np.linspace(y_min, y_max, y_size)  \n",
    "    mc = qe.tauchen(ρ, ν, n=z_size)\n",
    "    z_grid, Q = mc.state_values, mc.P\n",
    "\n",
    "    model = Model(β=β, a_0=a_0, a_1=a_1, γ=γ, c=c,\n",
    "                  y_size=y_size, z_size=z_size,\n",
    "                  y_grid=y_grid, z_grid=z_grid, Q=Q)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19054baf",
   "metadata": {},
   "source": [
    "Modify the model slightly to make it easier to pass to JAX functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3831ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_investment_model_jax():\n",
    "    \"Build a JAX-compatible version of the investment model.\"\n",
    "\n",
    "    model = create_investment_model()\n",
    "    β, a_0, a_1, γ, c, y_size, z_size, y_grid, z_grid, Q = model\n",
    "\n",
    "    # Break up parameters into static and nonstatic components\n",
    "    constants = β, a_0, a_1, γ, c\n",
    "    sizes = y_size, z_size\n",
    "    arrays = y_grid, z_grid, Q\n",
    "\n",
    "    # Shift arrays to the device (e.g., GPU)\n",
    "    arrays = tuple(map(jax.device_put, arrays))\n",
    "    return constants, sizes, arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e18419f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B(v, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    A vectorized version of the right-hand side of the Bellman equation \n",
    "    (before maximization), which is a 3D array representing\n",
    "\n",
    "        B(y, z, y′) = r(y, z, y′) + β Σ_z′ v(y′, z′) Q(z, z′).\"\n",
    "\n",
    "    for all (y, z, y′).\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack \n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    # Compute current rewards r(y, z, yp) as array r[i, j, ip]\n",
    "    y  = jnp.reshape(y_grid, (y_size, 1, 1))    # y[i]   ->  y[i, j, ip]\n",
    "    z  = jnp.reshape(z_grid, (1, z_size, 1))    # z[j]   ->  z[i, j, ip]\n",
    "    yp = jnp.reshape(y_grid, (1, 1, y_size))    # yp[ip] -> yp[i, j, ip]\n",
    "    r = (a_0 - a_1 * y + z - c) * y - γ * (yp - y)**2\n",
    "\n",
    "    # Calculate continuation rewards at all combinations of (y, z, yp)\n",
    "    v = jnp.reshape(v, (1, 1, y_size, z_size))  # v[ip, jp] -> v[i, j, ip, jp]\n",
    "    Q = jnp.reshape(Q, (1, z_size, 1, z_size))  # Q[j, jp]  -> Q[i, j, ip, jp]\n",
    "    EV = jnp.sum(v * Q, axis=3)                 # sum over last index jp\n",
    "\n",
    "    # Compute the right-hand side of the Bellman equation\n",
    "    return r + β * EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3fa68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r_σ(σ, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    Compute the array r_σ[i, j] = r[i, j, σ[i, j]], which gives current\n",
    "    rewards given policy σ.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack model\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    # Compute r_σ[i, j]\n",
    "    y = jnp.reshape(y_grid, (y_size, 1))\n",
    "    z = jnp.reshape(z_grid, (1, z_size))\n",
    "    yp = y_grid[σ]\n",
    "    r_σ = (a_0 - a_1 * y + z - c) * y - γ * (yp - y)**2\n",
    "\n",
    "    return r_σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50e3ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T(v, constants, sizes, arrays):\n",
    "    \"The Bellman operator.\"\n",
    "    return jnp.max(B(v, constants, sizes, arrays), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "544dd76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_greedy(v, constants, sizes, arrays):\n",
    "    \"Computes a v-greedy policy, returned as a set of indices.\"\n",
    "    return jnp.argmax(B(v, constants, sizes, arrays), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5d3ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_σ(v, σ, constants, sizes, arrays):\n",
    "    \"The σ-policy operator.\"\n",
    "\n",
    "    # Unpack model\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    r_σ = compute_r_σ(σ, constants, sizes, arrays)\n",
    "\n",
    "    # Compute the array v[σ[i, j], jp]\n",
    "    zp_idx = jnp.arange(z_size)\n",
    "    zp_idx = jnp.reshape(zp_idx, (1, 1, z_size))\n",
    "    σ = jnp.reshape(σ, (y_size, z_size, 1))\n",
    "    V = v[σ, zp_idx]      \n",
    "\n",
    "    # Convert Q[j, jp] to Q[i, j, jp] \n",
    "    Q = jnp.reshape(Q, (1, z_size, z_size))\n",
    "\n",
    "    # Calculate the expected sum Σ_jp v[σ[i, j], jp] * Q[i, j, jp]\n",
    "    Ev = np.sum(V * Q, axis=2)\n",
    "\n",
    "    return r_σ + β * np.sum(V * Q, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26cd976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_σ(v, σ, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    The value v_σ of a policy σ is defined as \n",
    "\n",
    "        v_σ = (I - β P_σ)^{-1} r_σ\n",
    "\n",
    "    Here we set up the linear map v -> R_σ v, where R_σ := I - β P_σ. \n",
    "\n",
    "    In the investment problem, this map can be expressed as\n",
    "\n",
    "        (R_σ v)(y, z) = v(y, z) - β Σ_z′ v(σ(y, z), z′) Q(z, z′)\n",
    "\n",
    "    Defining the map as above works in a more intuitive multi-index setting\n",
    "    (e.g. working with v[i, j] rather than flattening v to a one-dimensional\n",
    "    array) and avoids instantiating the large matrix P_σ.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    # Set up the array v[σ[i, j], jp]\n",
    "    zp_idx = jnp.arange(z_size)\n",
    "    zp_idx = jnp.reshape(zp_idx, (1, 1, z_size))\n",
    "    σ = jnp.reshape(σ, (y_size, z_size, 1))\n",
    "    V = v[σ, zp_idx]\n",
    "\n",
    "    # Expand Q[j, jp] to Q[i, j, jp]\n",
    "    Q = jnp.reshape(Q, (1, z_size, z_size))\n",
    "\n",
    "    # Compute and return v[i, j] - β Σ_jp v[σ[i, j], jp] * Q[j, jp]\n",
    "    return v - β * np.sum(V * Q, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71bbb45f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_value(σ, constants, sizes, arrays):\n",
    "    \"Get the value v_σ of policy σ by inverting the linear map R_σ.\"\n",
    "\n",
    "    # Unpack \n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    r_σ = compute_r_σ(σ, constants, sizes, arrays)\n",
    "\n",
    "    # Reduce R_σ to a function in v\n",
    "    partial_R_σ = lambda v: R_σ(v, σ, constants, sizes, arrays)\n",
    "\n",
    "    return jax.scipy.sparse.linalg.bicgstab(partial_R_σ, r_σ)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60efe0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Matrix versions\n",
    "\n",
    "Below are matrix versions of the operators discussed above, which reduce multi-index arrays to single index arrays.\n",
    "\n",
    "In general, these versions are less efficient and are mainly used for testing purposes.  They can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9de4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_P_σ(σ, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    Compute the transition probabilities across states as a multi-index array\n",
    "\n",
    "        P_σ[i, j, ip, jp] = (σ[i, j] == ip) * Q[j, jp]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack model\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    yp_idx = jnp.arange(y_size)\n",
    "    yp_idx = jnp.reshape(yp_idx, (1, 1, y_size, 1))\n",
    "    σ = jnp.reshape(σ, (y_size, z_size, 1, 1))\n",
    "    A = jnp.where(σ == yp_idx, 1, 0)\n",
    "    Q = jnp.reshape(Q, (1, z_size, 1, z_size))\n",
    "    P_σ = A * Q\n",
    "    return P_σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22fb50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_matrix_version(σ, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    Get the value v_σ of policy σ via\n",
    "\n",
    "        v_σ = (I - β P_σ)^{-1} r_σ\n",
    "\n",
    "    In this version we flatten the multi-index [i, j] for the state (y, z) to\n",
    "    a single index m and compute the vector r_σ[m] and matrix P_σ[m, mp]\n",
    "    giving transition probabilities across the single-index state.  Then we\n",
    "    solve the above equation using matrix inversion.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack \n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    # Obtain ordinary (multi-index) versions of r_σ and P_σ \n",
    "    r_σ = compute_r_σ(σ, constants, sizes, arrays)\n",
    "    P_σ = compute_P_σ(σ, constants, sizes, arrays)\n",
    "\n",
    "    # Reshape r_σ and P_σ for a single index state\n",
    "    n = y_size * z_size\n",
    "    P_σ = jnp.reshape(P_σ, (n, n))\n",
    "    r_σ = jnp.reshape(r_σ, n)\n",
    "\n",
    "    # Solve\n",
    "    v_σ = jnp.linalg.solve(np.identity(n) - β * P_σ, r_σ)\n",
    "\n",
    "    # Return as multi-index array\n",
    "    return jnp.reshape(v_σ, (y_size, z_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5972281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_σ_matrix_version(v, σ, constants, sizes, arrays):\n",
    "    \"The σ-policy operator, single index version.\"\n",
    "\n",
    "    # Unpack model\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    # Obtain ordinary (multi-index) versions of r_σ and P_σ \n",
    "    r_σ = compute_r_σ(σ, constants, sizes, arrays)\n",
    "    P_σ = compute_P_σ(σ, constants, sizes, arrays)\n",
    "\n",
    "    # Reshape r_σ and P_σ for a single index state\n",
    "    n = y_size * z_size\n",
    "    P_σ = jnp.reshape(P_σ, (n, n))\n",
    "    r_σ = jnp.reshape(r_σ, n)\n",
    "    v = jnp.reshape(v, n)\n",
    "\n",
    "    # Iterate with T_σ using matrix routines\n",
    "    new_v = r_σ + β * P_σ @ v\n",
    "\n",
    "    # Return as multi-index array\n",
    "    return jnp.reshape(new_v, (y_size, z_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a158525f",
   "metadata": {},
   "source": [
    "## Building JIT compiled versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f083ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = jax.jit(B, static_argnums=(2,))\n",
    "compute_r_σ = jax.jit(compute_r_σ, static_argnums=(2,))\n",
    "T = jax.jit(T, static_argnums=(2,))\n",
    "get_greedy = jax.jit(get_greedy, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8484ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_value = jax.jit(get_value, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbbf4ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_σ = jax.jit(T_σ, static_argnums=(3,))\n",
    "R_σ = jax.jit(R_σ, static_argnums=(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "946f4dd7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "get_value_matrix_version = jax.jit(get_value_matrix_version, static_argnums=(2,))\n",
    "T_σ_matrix_version = jax.jit(T_σ_matrix_version, static_argnums=(3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2aed7c",
   "metadata": {},
   "source": [
    "## Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c476b2f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def value_iteration(model, tol=1e-5):\n",
    "    \"Implements VFI.\"\n",
    "\n",
    "    constants, sizes, arrays = model\n",
    "    _T = lambda v: T(v, constants, sizes, arrays)\n",
    "    vz = jnp.zeros(sizes)\n",
    "\n",
    "    v_star = successive_approx(_T, vz, tolerance=tol)\n",
    "    return get_greedy(v_star, constants, sizes, arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f14db25",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def policy_iteration(model, matrix_version=False):\n",
    "    \"Howard policy iteration routine.\"\n",
    "\n",
    "    constants, sizes, arrays = model\n",
    "    if matrix_version:\n",
    "        _get_value = get_value_matrix_version\n",
    "    else:\n",
    "        _get_value = get_value\n",
    "\n",
    "    vz = jnp.zeros(sizes)\n",
    "    σ = jnp.zeros(sizes, dtype=int)\n",
    "    i, error = 0, 1.0\n",
    "    while error > 0:\n",
    "        v_σ = _get_value(σ, constants, sizes, arrays)\n",
    "        σ_new = get_greedy(v_σ, constants, sizes, arrays)\n",
    "        error = jnp.max(np.abs(σ_new - σ))\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        print(f\"Concluded loop {i} with error {error}.\")\n",
    "    return σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8839e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimistic_policy_iteration(model, tol=1e-5, m=10, matrix_version=False):\n",
    "    \"Implements the OPI routine.\"\n",
    "    constants, sizes, arrays = model\n",
    "    if matrix_version:\n",
    "        _T_σ = T_σ_matrix_version\n",
    "    else:\n",
    "        _T_σ = T_σ\n",
    "\n",
    "    v = jnp.zeros(sizes)\n",
    "    error = tol + 1\n",
    "    while error > tol:\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, constants, sizes, arrays)\n",
    "        for _ in range(m):\n",
    "            v = _T_σ(v, σ, constants, sizes, arrays)\n",
    "        error = jnp.max(np.abs(v - last_v))\n",
    "    return get_greedy(v, constants, sizes, arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a0538",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd81e369",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HPI.\n",
      "Concluded loop 1 with error 50.\n",
      "Concluded loop 2 with error 26.\n",
      "Concluded loop 3 with error 17.\n",
      "Concluded loop 4 with error 10.\n",
      "Concluded loop 5 with error 7.\n",
      "Concluded loop 6 with error 4.\n",
      "Concluded loop 7 with error 3.\n",
      "Concluded loop 8 with error 1.\n",
      "Concluded loop 9 with error 1.\n",
      "Concluded loop 10 with error 1.\n",
      "Concluded loop 11 with error 1.\n",
      "Concluded loop 12 with error 0.\n",
      "TOC: Elapsed: 0:00:0.08\n",
      "[[ 2  2  2 ...  6  6  6]\n",
      " [ 3  3  3 ...  7  7  7]\n",
      " [ 4  4  4 ...  7  7  7]\n",
      " ...\n",
      " [82 82 82 ... 86 86 86]\n",
      " [83 83 83 ... 86 86 86]\n",
      " [84 84 84 ... 87 87 87]]\n",
      "HPI completed in 0.08669376373291016 seconds.\n"
     ]
    }
   ],
   "source": [
    "model = create_investment_model_jax()\n",
    "print(\"Starting HPI.\")\n",
    "qe.tic()\n",
    "out = policy_iteration(model)\n",
    "elapsed = qe.toc()\n",
    "print(out)\n",
    "print(f\"HPI completed in {elapsed} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "796b09a0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting VFI.\n",
      "TOC: Elapsed: 0:00:0.65\n",
      "[[ 2  2  2 ...  6  6  6]\n",
      " [ 3  3  3 ...  7  7  7]\n",
      " [ 4  4  4 ...  7  7  7]\n",
      " ...\n",
      " [82 82 82 ... 86 86 86]\n",
      " [83 83 83 ... 86 86 86]\n",
      " [84 84 84 ... 87 87 87]]\n",
      "VFI completed in 0.6575298309326172 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting VFI.\")\n",
    "qe.tic()\n",
    "out = value_iteration(model)\n",
    "elapsed = qe.toc()\n",
    "print(out)\n",
    "print(f\"VFI completed in {elapsed} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b540b53a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OPI.\n",
      "TOC: Elapsed: 0:00:0.28\n",
      "[[ 2  2  2 ...  6  6  6]\n",
      " [ 3  3  3 ...  7  7  7]\n",
      " [ 4  4  4 ...  7  7  7]\n",
      " ...\n",
      " [82 82 82 ... 86 86 86]\n",
      " [83 83 83 ... 86 86 86]\n",
      " [84 84 84 ... 87 87 87]]\n",
      "OPI completed in 0.28416991233825684 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting OPI.\")\n",
    "qe.tic()\n",
    "out = optimistic_policy_iteration(model, m=100)\n",
    "elapsed = qe.toc()\n",
    "print(out)\n",
    "print(f\"OPI completed in {elapsed} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d8b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
